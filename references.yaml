# References Database - RoyalBit Asimov
# Verified sources for ADRs and documentation
# Format: category â†’ sources with metadata

rag_vs_long_context:
  - title: "Retrieval Augmented Generation or Long-Context LLMs? A Comprehensive Study and Hybrid Approach"
    url: https://arxiv.org/abs/2407.16833
    authors: ["Zhuowan Li", "Cheng Li", "Mingyang Zhang", "Qiaozhu Mei", "Michael Bendersky"]
    organization: Google DeepMind / University of Michigan
    date: 2024-07
    key_finding: "LC outperforms RAG by 3.6-13.1% depending on model"

  - title: "Long Context vs. RAG for LLMs: An Evaluation and Revisits"
    url: https://arxiv.org/abs/2501.01880
    authors: ["Xinze Li", "Yixin Cao", "Yubo Ma", "Aixin Sun"]
    organization: NTU Singapore
    date: 2025-01
    key_finding: "LC generally outperforms RAG in QA, RAG better for dialogue"

  - title: "Long Context RAG Performance of LLMs"
    url: https://www.databricks.com/blog/long-context-rag-performance-llms
    organization: Databricks
    date: 2024-08
    key_finding: "2000+ experiments, most models degrade after 32-64k tokens"

  - title: "Lost in the Middle: How Language Models Use Long Contexts"
    url: https://arxiv.org/abs/2307.03172
    authors: ["Nelson F. Liu", "Kevin Lin", "John Hewitt", "Ashwin Paranjape", "Michele Bevilacqua", "Fabio Petroni", "Percy Liang"]
    organization: Stanford
    date: 2024
    key_finding: "U-shaped performance curve - models struggle with middle-positioned information"

  - title: "Context Rot: How Increasing Input Tokens Impacts LLM Performance"
    url: https://research.trychroma.com/context-rot
    organization: Chroma
    date: 2025
    key_finding: "Popular LLMs effectively utilize only 10-20% of context"

  - title: "Contextual Retrieval"
    url: https://www.anthropic.com/news/contextual-retrieval
    organization: Anthropic
    date: 2024-09-19
    key_finding: "Reduces failed retrievals by 49%, with reranking by 67%"

  - title: "RAG vs. Context-Window in GPT-4: accuracy, cost, & latency"
    url: https://www.copilotkit.ai/blog/rag-vs-context-window-in-gpt-4
    organization: CopilotKit
    date: 2024
    key_finding: "RAG achieves same performance at 4% of the cost"

mcp_overhead:
  - title: "Code execution with MCP: Building more efficient agents"
    url: https://www.anthropic.com/engineering/code-execution-with-mcp
    authors: ["Adam Jones", "Conor Kelly"]
    organization: Anthropic
    date: 2025-11-04
    key_finding: "134K tokens before optimization, 98.7% reduction possible"

  - title: "Mitigating Token Bloat in MCP (SEP-1576)"
    url: https://github.com/modelcontextprotocol/modelcontextprotocol/issues/1576
    authors: ["Zeze Chang", "Jinyang Li", "Zhen Cao"]
    organization: Huawei
    date: 2025-09-30
    key_finding: "50-1000 tokens per tool definition"

  - title: "Reducing MCP token usage by 100x"
    url: https://www.speakeasy.com/blog/how-we-reduced-token-usage-by-100x-dynamic-toolsets-v2
    author: Chase Crumbaugh
    organization: Speakeasy
    date: 2025-11-17
    key_finding: "90-96% reduction with dynamic toolsets"

  - title: "MCP vs CLI: Benchmarking Tools for Coding Agents"
    url: https://mariozechner.at/posts/2025-08-15-mcp-vs-cli/
    author: Mario Zechner
    date: 2025-08-15
    key_finding: "MCP and CLI roughly equivalent for complex tasks"

  - title: "MCP Official Specification"
    url: https://modelcontextprotocol.io/specification/latest
    organization: Anthropic / Linux Foundation
    date: 2025-11-25
    key_finding: "Protocol revision 2025-11-25"

agentic_frameworks:
  - title: "Benchmarking Multi-Agent Architectures"
    url: https://blog.langchain.com/benchmarking-multi-agent-architectures/
    author: Will Fu-Hinthorn
    organization: LangChain
    date: 2025-06-11
    key_finding: "Single agent falls sharply at 2+ distractor domains"

  - title: "Benchmarking Single Agent Performance"
    url: https://blog.langchain.com/react-agent-benchmarking/
    organization: LangChain
    date: 2025-02-10
    key_finding: "Both more context and more tools degrade agent performance"

  - title: "Context Engineering for Agents"
    url: https://blog.langchain.com/context-engineering-for-agents/
    organization: LangChain
    date: 2025-07-02
    key_finding: "Four context failure modes identified"

  - title: "Benchmarking Agentic AI Frameworks in Analytics Workflows"
    url: https://research.aimultiple.com/agentic-analytics/
    authors: ["Cem Dilmegani", "Nazli Sipi"]
    organization: AIMultiple
    date: 2025
    key_finding: "CrewAI 37% tool success rate, LangGraph 100%"

  - title: "Research shows 'more agents' isn't a reliable path to better enterprise AI"
    url: https://venturebeat.com/orchestration/research-shows-more-agents-isnt-a-reliable-path-to-better-enterprise-ai
    organization: VentureBeat
    date: 2025-12-23
    key_finding: "17.2x error amplification with independent agents, max 3-4 agents effective"

  - title: "Don't Build Multi-Agents"
    url: https://cognition.ai/blog/dont-build-multi-agents
    organization: Cognition (Devin)
    date: 2025-06
    key_finding: "All agents should read/write to same context"

dynamic_orchestration:
  - title: "Building Effective AI Agents"
    url: https://www.anthropic.com/research/building-effective-agents
    authors: ["Erik Schluntz", "Barry Zhang"]
    organization: Anthropic
    date: 2024-12-19
    key_finding: "Simple, composable patterns beat complex frameworks"

  - title: "How we built our multi-agent research system"
    url: https://www.anthropic.com/engineering/multi-agent-research-system
    authors: ["Jeremy Hadfield", "Barry Zhang", "Kenneth Lien", "Florian Scholz", "Jeremy Fox", "Daniel Ford"]
    organization: Anthropic
    date: 2025-06-13
    key_finding: "90.2% improvement, token usage explains 80% of performance variance"

  - title: "Claude Code Subagents Documentation"
    url: https://code.claude.com/docs/en/sub-agents
    organization: Anthropic
    date: 2025
    key_finding: "Task tool + subagents architecture"

  - title: "Introducing 100K Context Windows"
    url: https://www.anthropic.com/news/100k-context-windows
    organization: Anthropic
    date: 2023-05
    key_finding: "Located needle in 72K tokens in 22 seconds"

  - title: "S-Agents: Self-organizing Agents in Open-ended Environments"
    url: https://arxiv.org/abs/2402.04578
    authors: ["Jiaqi Chen", "Yuxian Jiang", "Jiachen Lu", "Li Zhang"]
    date: 2024-02
    key_finding: "Tree of Agents with dynamic workflow"

  - title: "Multi-Agent Collaboration Mechanisms Survey"
    url: https://arxiv.org/html/2501.06322v1
    date: 2025-01
    key_finding: "Social behaviors autonomously emerge within agent groups"

context_utilization:
  - title: "Context Fragmentation Costs"
    url: https://arya.ai/blog/ai-context-fragmentation
    organization: Arya.ai
    date: 2025
    key_finding: "Multi-agent task costing $0.10 can cost $1.50 with context sharing"

  - title: "Context Engineering: Why Agents Fail in Production"
    url: https://inkeep.com/blog/context-engineering-why-agents-fail
    organization: Inkeep
    date: 2025
    key_finding: "Full-file context: 95% accuracy vs fragmented: 80%"

  - title: "Why Multi-Agent LLM Systems Fail"
    url: https://orq.ai/blog/why-do-multi-agent-llm-systems-fail
    organization: Orq.ai
    date: 2025
    key_finding: "Lack of shared context results in fragmented logic"

  - title: "Multi-Agent Coordination Failure Mitigation"
    url: https://galileo.ai/blog/multi-agent-coordination-failure-mitigation
    organization: Galileo
    date: 2025
    key_finding: "Architectural limitations in maintaining shared context"

gemini_extended_context:
  - title: "Gemini 1.5: Unlocking multimodal understanding across millions of tokens"
    url: https://arxiv.org/abs/2403.05530
    organization: Google
    date: 2024-03
    key_finding: ">99.7% recall up to 1M tokens, 99.2% at 10M tokens"

  - title: "The Needle in the Haystack Test"
    url: https://cloud.google.com/blog/products/ai-machine-learning/the-needle-in-the-haystack-test-and-how-gemini-pro-solves-it
    organization: Google Cloud
    date: 2024
    key_finding: "100% accuracy up to 107 hours of audio"

# LLM Harmful Behavior Countermeasures (ADR-050, ADR-051)
# Added: 2025-12-31

economic_incentive_countermeasures:
  - title: "Harnessing the Reasoning Economy: A Survey of Efficient Reasoning for Large Language Models"
    url: https://arxiv.org/abs/2503.24377
    date: 2025-03
    key_finding: "LRMs waste resources on overthinking while underthinking complex questions"

  - title: "Thoughts Are All Over the Place: On the Underthinking of o1-Like LLMs"
    url: https://arxiv.org/abs/2501.18585
    date: 2025-01
    key_finding: "225% more tokens on incorrect answers, 418% more thought-switching"

  - title: "Do Not Think That Much for 2+3! Tempering Reasoning Efficiency of LLMs"
    url: https://arxiv.org/abs/2503.16419
    date: 2025-03
    key_finding: "Survey on stopping LLM overthinking"

  - title: "How to Get Better Outputs from Your Large Language Model"
    url: https://developer.nvidia.com/blog/how-to-get-better-outputs-from-your-large-language-model/
    organization: NVIDIA
    date: 2024
    key_finding: "Chain-of-thought prompting and temperature tuning strategies"

  - title: "State of LLM Reasoning and Inference Scaling"
    url: https://magazine.sebastianraschka.com/p/state-of-llm-reasoning-and-inference-scaling
    author: Sebastian Raschka
    date: 2025
    key_finding: "s1 paper: 'Wait' tokens improve self-verification"

  - title: "LLM Evaluation Metrics: Everything You Need for LLM Evaluation"
    url: https://www.confident-ai.com/blog/llm-evaluation-metrics-everything-you-need-for-llm-evaluation
    organization: Confident AI
    date: 2025
    key_finding: "LLM-as-a-judge evaluation framework"

  - title: "OptimalThinkingBench: Benchmarking LLM Reasoning Economy"
    url: https://arxiv.org/html/2508.13141v1
    date: 2025-08
    key_finding: "Benchmark for measuring reasoning efficiency"

  - title: "OverThink: Slowdown Attacks on Reasoning LLMs"
    url: https://arxiv.org/abs/2502.02542
    date: 2025-02
    key_finding: "Adversarial attacks exploit reasoning inefficiency"

system_prompt_override_countermeasures:
  - title: "The Instruction Hierarchy: Training LLMs to Prioritize Privileged Instructions"
    url: https://arxiv.org/abs/2404.13208
    organization: OpenAI
    date: 2024-04
    key_finding: "63% better resistance to attacks with hierarchy-aware training"

  - title: "LLM Prompt Injection Prevention Cheat Sheet"
    url: https://cheatsheetseries.owasp.org/cheatsheets/LLM_Prompt_Injection_Prevention_Cheat_Sheet.html
    organization: OWASP
    date: 2025
    key_finding: "Comprehensive defense strategies for prompt injection"

  - title: "Defending Against Indirect Prompt Injection Attacks With Spotlighting"
    url: https://arxiv.org/abs/2403.14720
    organization: Microsoft
    date: 2024-03
    key_finding: "Datamarking reduces attack success from >50% to <2%"

  - title: "Instruction Hierarchy in LLMs"
    url: https://ylanglabs.com/blogs/instruction-hierarchy-in-llms
    organization: Ylang Labs
    date: 2024
    key_finding: "Four-tier priority hierarchy documentation"

  - title: "Securing LLM Systems Against Prompt Injection"
    url: https://developer.nvidia.com/blog/securing-llm-systems-against-prompt-injection/
    organization: NVIDIA AI Red Team
    date: 2024
    key_finding: "Treat all LLM outputs as potentially malicious"

  - title: "Why LLMs Fail in Multi-Turn Conversations and How to Fix It"
    url: https://www.prompthub.us/blog/why-llms-fail-in-multi-turn-conversations-and-how-to-fix-it
    organization: PromptHub
    date: 2025
    key_finding: "40% performance drop in multi-turn vs single-turn"

  - title: "LLMs Get Lost In Multi-Turn Conversation"
    url: https://arxiv.org/abs/2505.06120
    date: 2025-05
    key_finding: "Models lock-in on early mistakes"

  - title: "AutoDefense: Multi-Agent LLM Defense against Jailbreak Attacks"
    url: https://arxiv.org/abs/2403.04783
    date: 2024-03
    key_finding: "Multi-agent approach to defense"

  - title: "Context Engineering in LLM-Based Agents"
    url: https://jtanruan.medium.com/context-engineering-in-llm-based-agents-d670d6b439bc
    date: 2025
    key_finding: "Dynamic state injection techniques"

sycophancy_countermeasures:
  - title: "Sycophancy in Large Language Models: Causes and Mitigations"
    url: https://arxiv.org/abs/2411.15287
    date: 2024-11
    key_finding: "Comprehensive survey of sycophancy causes and fixes"

  - title: "Towards Understanding Sycophancy in Language Models"
    url: https://www.anthropic.com/research/towards-understanding-sycophancy-in-language-models
    organization: Anthropic
    date: 2023
    key_finding: "RLHF-trained models consistently exhibit sycophancy"

  - title: "Sycophancy is the first LLM dark pattern"
    url: https://www.seangoedecke.com/ai-sycophancy/
    author: Sean Goedecke
    date: 2024
    key_finding: "Sycophancy as systematic design flaw"

  - title: "Understanding Sycophancy in LLMs"
    url: https://www.giskard.ai/knowledge/when-your-ai-agent-tells-you-what-you-want-to-hear-understanding-sycophancy-in-llms
    organization: Giskard
    date: 2024
    key_finding: "Detection and mitigation strategies"

  - title: "How to Make ChatGPT Brutally Honest"
    url: https://medium.com/@MyDigitalMusings/how-to-make-chatgpt-brutally-honest-a59584cd5cb8
    date: 2024
    key_finding: "Practical anti-sycophancy prompts"

  - title: "Stop Being So Nice: How to Avoid AI Complacency"
    url: https://jokiruiz.com/software/stop-being-so-nice-how-to-avoid-ai-complacency-in-chatgpt-and-beyond/
    author: Joki Ruiz
    date: 2024
    key_finding: "Devil's advocate and third-person techniques"

  - title: "Detecting and Evaluating Sycophancy Bias"
    url: https://huggingface.co/blog/Rakshit122/sycophantic-ai
    organization: Hugging Face
    date: 2024
    key_finding: "Benchmark methodologies for sycophancy detection"

  - title: "SycEval: Evaluating LLM Sycophancy"
    url: https://arxiv.org/abs/2502.08177
    date: 2025-02
    key_finding: "58% sycophancy rate across major models"

  - title: "ELEPHANT: Measuring Social Sycophancy in LLMs"
    url: https://arxiv.org/abs/2505.13995
    date: 2025-05
    key_finding: "Open-ended sycophancy evaluation benchmark"

  - title: "Findings from Anthropic-OpenAI Alignment Evaluation"
    url: https://alignment.anthropic.com/2025/openai-findings/
    organization: Anthropic
    date: 2025
    key_finding: "Joint evaluation confirms sycophancy in all models"

  - title: "Simple synthetic data reduces sycophancy in large language models"
    url: https://arxiv.org/abs/2308.03958
    organization: Google Research
    date: 2023-08
    key_finding: "Training-level mitigation via synthetic data"

output_verification:
  - title: "LLM Hallucinations in 2025: How to Understand and Tackle AI's Most Persistent Quirk"
    url: https://www.lakera.ai/blog/guide-to-hallucinations-in-large-language-models
    organization: Lakera
    date: 2025
    key_finding: "Comprehensive guide to hallucination mitigation"

  - title: "SafetyNet: Detecting Harmful Outputs in LLMs"
    url: https://arxiv.org/abs/2505.14300
    date: 2025-05
    key_finding: "96% accuracy in detecting harmful outputs"

  - title: "Detecting hallucinations in large language models using semantic entropy"
    url: https://www.nature.com/articles/s41586-024-07421-0
    organization: Nature
    date: 2024
    key_finding: "AUROC 0.790 for hallucination detection via semantic entropy"

  - title: "Hallucination Detection in LLMs with Metamorphic Relations (MetaQA)"
    url: https://arxiv.org/abs/2502.15844
    date: 2025-02
    key_finding: "Self-contained detection requiring no external resources"

  - title: "OpenFactCheck: Building Customized Fact-Checking Systems"
    url: https://arxiv.org/abs/2405.05583
    date: 2024-05
    key_finding: "90%+ claims factually correct, but logical failures persist"

  - title: "Prevent factual errors from LLM hallucinations with Automated Reasoning"
    url: https://aws.amazon.com/blogs/aws/prevent-factual-errors-from-llm-hallucinations-with-mathematically-sound-automated-reasoning-checks-preview/
    organization: AWS
    date: 2024-12
    key_finding: "Mathematical logic-based verification"

  - title: "10 LLM Security Tools to Know in 2025"
    url: https://www.pynt.io/learning-hub/llm-security/10-llm-security-tools-to-know
    organization: Pynt
    date: 2025
    key_finding: "Overview of LLM Guard, Garak, Rebuff, Vigil"

  - title: "LLM cross-validation frameworks: Mitigating hallucinations"
    url: https://journalwjaets.com/node/800
    organization: World Journal of Advanced Engineering
    date: 2025
    key_finding: "Dual-LLM verification reduces hallucinations by 86%"

  - title: "A scalable framework for evaluating multiple language models"
    url: https://www.nature.com/articles/s41598-025-15203-5
    organization: Scientific Reports
    date: 2025
    key_finding: "Cross-provider validation framework"

  - title: "DarkPatterns-LLM: A Multi-Layer Benchmark"
    url: https://arxiv.org/abs/2512.22470
    date: 2025-12
    key_finding: "Seven harm categories diagnostic framework"

  - title: "OWASP Top 10 for LLMs 2025"
    url: https://www.invicti.com/blog/web-security/owasp-top-10-risks-llm-security-2025
    organization: Invicti
    date: 2025
    key_finding: "Updated LLM security risks"

  - title: "LLM Guard - Open Source Security Toolkit"
    url: https://github.com/protectai/llm-guard
    organization: Protect AI
    license: MIT
    key_finding: "Prompt injection detection and output sanitization"

# Additional References Verified 2025-12-31
# Sources referenced in ADRs and documentation

academic_papers:
  - title: "Energy and Policy Considerations for Deep Learning in NLP"
    url: https://arxiv.org/abs/1906.02243
    organization: University of Massachusetts Amherst
    date: 2019-06
    key_finding: "Analyzing computational cost and carbon footprint of training large NLP models"

  - title: "Constitutional AI: Harmlessness from AI Feedback"
    url: https://arxiv.org/abs/2212.08073
    organization: Anthropic
    date: 2022-12
    key_finding: "Introduces CAI for training helpful, harmless, honest AI using AI-generated feedback"

  - title: "The Impact of AI on Developer Productivity: Evidence from GitHub Copilot"
    url: https://arxiv.org/abs/2302.06590
    organization: GitHub / Microsoft Research
    date: 2023-02
    key_finding: "Copilot users completed tasks 55.8% faster in RCT"

  - title: "GPT-4 Technical Report"
    url: https://arxiv.org/abs/2303.08774
    organization: OpenAI
    date: 2023-03
    key_finding: "Technical report introducing GPT-4 multimodal model"

  - title: "LayerSkip: Enabling Early Exit Inference and Self-Speculative Decoding"
    url: https://arxiv.org/abs/2404.16710
    organization: Meta AI
    date: 2024-04
    key_finding: "Accelerates LLM inference without separate draft models"

  - title: "Sycophantic AI Decreases Prosocial Intentions"
    url: https://arxiv.org/abs/2510.01395
    organization: Stanford University
    date: 2025-10
    key_finding: "Sycophantic AI decreases prosocial intentions and increases dependence"

  - title: "A Survey of Self-Evolving Agents"
    url: https://arxiv.org/abs/2507.21046
    organization: University of Illinois / Princeton
    date: 2025-07
    key_finding: "Survey on self-evolving AI agents and path to AGI"

  - title: "The Economic Trade-offs of LLMs: A Case Study"
    url: https://arxiv.org/html/2306.07402
    organization: LivePerson
    date: 2023-06
    key_finding: "ENCS framework showing distilled GPT-2 better ROI than GPT-3 for customer service"

  - title: "Scaling LLM Test-Time Compute Optimally"
    url: https://arxiv.org/html/2408.03314v1
    organization: UC Berkeley / Google DeepMind
    date: 2024-08
    key_finding: "Smaller model + test-time compute can outperform 14x larger model"

  - title: "SpecEE: Accelerating LLM Inference with Speculative Early Exiting"
    url: https://arxiv.org/html/2504.08850
    date: 2025-04
    key_finding: "2.25x-2.43x speedup via speculative decoding + early exiting"

  - title: "Red Teaming Prompt Injection in LLMs"
    url: https://arxiv.org/html/2505.04806v1
    date: 2025-05
    key_finding: "GPT-4 87.2% attack success rate, roleplay jailbreaks 89.6%"

  - title: "Defending Against Prompt Injection with Defensive Tokens"
    url: https://arxiv.org/html/2507.07974v1
    organization: UC Berkeley / UMD
    date: 2025-07
    key_finding: "5 optimized tokens reduce attack success by order of magnitude"

  - title: "Computational Economics in LLMs"
    url: https://arxiv.org/html/2508.10426
    date: 2025-08
    key_finding: "40% FLOPS reduction with negligible performance loss via incentive-driven training"

  - title: "Shallow-Deep Networks: Understanding Network Overthinking"
    url: https://arxiv.org/pdf/1810.07052
    organization: University of Maryland
    date: 2018-10
    key_finding: "Introduces concept of overthinking in deep networks with early exit mechanisms"

  - title: "A Survey on Hallucination in LLMs"
    url: https://dl.acm.org/doi/10.1145/3703155
    organization: ACM
    date: 2024
    key_finding: "Comprehensive survey on LLM hallucination principles and taxonomy"

  - title: "RLHF: Whose Culture, Whose Values"
    url: https://link.springer.com/article/10.1007/s13347-025-00861-0
    organization: Springer / Philosophy & Technology
    date: 2025
    key_finding: "Arguments for pluralism in RLHF through diverse feedback groups"

  - title: "Peer Review of GPT-4 Technical Report"
    url: https://pmc.ncbi.nlm.nih.gov/articles/PMC10795998/
    organization: PLOS Digital Health
    date: 2024
    key_finding: "Limitations in training transparency, confidence estimations, privacy concerns"

  - title: "InstructGPT: Training LLMs with Human Feedback"
    url: https://cdn.openai.com/papers/Training_language_models_to_follow_instructions_with_human_feedback.pdf
    organization: OpenAI
    date: 2022
    key_finding: "RLHF produces models better at following intent, more truthful, less harmful"

  - title: "Economic Incentives and Mass-Market Training"
    url: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5181079
    organization: SSRN
    date: 2025
    key_finding: "Financial pressures incentivized engagement over accuracy, making hallucinations predictable"

anthropic_official:
  - title: "Anthropic Homepage"
    url: https://www.anthropic.com
    organization: Anthropic
    key_finding: "Public benefit corporation building AI for humanity's well-being"

  - title: "Claude Opus 4.5"
    url: https://www.anthropic.com/claude/opus
    organization: Anthropic
    key_finding: "80.9% SWE-bench, 66.3% OSWorld, $5/$25 per million tokens"

  - title: "Claude Opus 4.5 Announcement"
    url: https://www.anthropic.com/news/claude-opus-4-5
    organization: Anthropic
    key_finding: "76% fewer output tokens than predecessors for equivalent performance"

  - title: "Claude Sonnet 4.5 Announcement"
    url: https://www.anthropic.com/news/claude-sonnet-4-5
    organization: Anthropic
    key_finding: "Best coding model, 61.4% OSWorld, $3/$15 per million tokens"

  - title: "Claude Code Best Practices"
    url: https://www.anthropic.com/engineering/claude-code-best-practices
    organization: Anthropic
    key_finding: "CLAUDE.md, custom commands, TDD, git worktrees, headless mode"

  - title: "Enabling Claude Code to Work More Autonomously"
    url: https://www.anthropic.com/news/enabling-claude-code-to-work-more-autonomously
    organization: Anthropic
    key_finding: "Checkpoints, VS Code extension, Claude Agent SDK"

  - title: "Constitutional AI: Harmlessness from AI Feedback"
    url: https://www.anthropic.com/research/constitutional-ai-harmlessness-from-ai-feedback
    organization: Anthropic
    key_finding: "Self-critique + RLAIF for precise behavior control without human labels"

  - title: "Sycophancy to Subterfuge: Reward Tampering"
    url: https://www.anthropic.com/research/reward-tampering
    organization: Anthropic
    key_finding: "Sycophantic models can generalize to reward tampering when given code access"

  - title: "Pretraining Data Filtering for Safety"
    url: https://alignment.anthropic.com/2025/pretraining-data-filtering/
    organization: Anthropic
    date: 2025
    key_finding: "Filtering CBRN content reduced harmful capabilities by 33%"

  - title: "Enabling and Using Web Search"
    url: https://support.claude.com/en/articles/10684626-enabling-and-using-web-search
    organization: Anthropic
    key_finding: "Web search with citations for Opus/Sonnet/Haiku 4.5 and Claude 4"

claude_code_docs:
  - title: "Claude Code Product Page"
    url: https://claude.com/claude-code
    organization: Anthropic
    key_finding: "AI coding agent for terminal, IDE, Slack, web - Pro $17/mo to Max $200/mo"

  - title: "Claude Code Checkpointing"
    url: https://code.claude.com/docs/en/checkpointing
    organization: Anthropic
    key_finding: "File edit tracking, Esc+Esc or /rewind, checkpoints persist 30 days"

  - title: "Claude Code Hooks Reference"
    url: https://code.claude.com/docs/en/hooks
    organization: Anthropic
    key_finding: "Custom bash commands or LLM evaluations at lifecycle events via settings.json"

  - title: "Claude Code Memory"
    url: https://docs.claude.com/en/docs/claude-code/memory
    organization: Anthropic
    key_finding: "Hierarchical CLAUDE.md files with @import syntax"

  - title: "What's New in Claude 4.5"
    url: https://docs.claude.com/en/docs/about-claude/models/whats-new-claude-4-5
    organization: Anthropic
    key_finding: "Opus 4.5, Sonnet 4.5, Haiku 4.5 with effort parameter and tool search"

  - title: "Claude Context Windows"
    url: https://docs.claude.com/en/docs/build-with-claude/context-windows
    organization: Anthropic
    key_finding: "Sonnet 4/4.5 supports 1M tokens (beta tier 4), native context awareness"

  - title: "Claude Extended Thinking"
    url: https://platform.claude.com/docs/en/build-with-claude/extended-thinking
    organization: Anthropic
    key_finding: "Extended thinking mode documentation"

openai_official:
  - title: "OpenAI Model Spec (2025-02-12)"
    url: https://model-spec.openai.com/2025-02-12.html
    organization: OpenAI
    date: 2025-02
    key_finding: "Comprehensive model behavior spec: chain of command, safety principles"

  - title: "Sycophancy in GPT-4o"
    url: https://openai.com/index/sycophancy-in-gpt-4o/
    organization: OpenAI
    key_finding: "Rolled back update that was overly flattering and agreeable"

  - title: "Why Language Models Hallucinate"
    url: https://openai.com/index/why-language-models-hallucinate/
    organization: OpenAI
    key_finding: "Training rewards guessing over acknowledging uncertainty"

  - title: "OpenAI Cost Optimization Guide"
    url: https://platform.openai.com/docs/guides/cost-optimization
    organization: OpenAI
    key_finding: "Token reduction, Batch API, flex processing strategies"

github_resources:
  - title: "GitHub Copilot Coding Agent"
    url: https://docs.github.com/en/copilot/concepts/coding-agent/coding-agent
    organization: GitHub
    key_finding: "Autonomous agent in GitHub Actions, opens PRs, for Pro/Business/Enterprise"

  - title: "GitHub Copilot Productivity Research"
    url: https://github.blog/news-insights/research/research-quantifying-github-copilots-impact-on-developer-productivity-and-happiness/
    organization: GitHub
    key_finding: "55% faster task completion, 90% report faster repetitive tasks"

  - title: "Claude Sonnet 4.5 GA in GitHub Copilot"
    url: https://github.blog/changelog/2025-10-13-anthropics-claude-sonnet-4-5-is-now-generally-available-in-github-copilot/
    organization: GitHub
    date: 2025-10-13
    key_finding: "GA for Enterprise, Business, Pro, Pro+ across all IDEs"

  - title: "Claude Haiku 4.5 in GitHub Copilot"
    url: https://github.blog/changelog/2025-10-15-anthropics-claude-haiku-4-5-is-in-public-preview-for-github-copilot/
    organization: GitHub
    date: 2025-10-15
    key_finding: "High performance with faster speeds in public preview"

  - title: "Claude Opus 4.5 in GitHub Copilot"
    url: https://github.blog/changelog/2025-11-24-claude-opus-4-5-is-in-public-preview-for-github-copilot/
    organization: GitHub
    date: 2025-11-24
    key_finding: "Cut token usage in half while surpassing coding benchmarks"

  - title: "cloc - Count Lines of Code"
    url: https://github.com/AlDanial/cloc
    author: Al Danial
    key_finding: "Perl-based tool counting blank, comment, and physical lines in many languages"

  - title: "garak - LLM Vulnerability Scanner"
    url: https://github.com/leondz/garak
    organization: NVIDIA
    key_finding: "Probes for hallucination, data leakage, prompt injection, toxicity, jailbreaks"

  - title: "Rebuff - Prompt Injection Detector"
    url: https://github.com/protectai/rebuff
    organization: Protect AI
    key_finding: "Multi-layer defense: heuristics, LLM detection, vector DB, canary tokens"

  - title: "System Prompts Leaks Collection"
    url: https://github.com/asgeirtj/system_prompts_leaks
    author: asgeirtj
    key_finding: "Community-maintained extracted system prompts from ChatGPT, Claude, Gemini"

  - title: "CL4R1T4S - AI System Prompts"
    url: https://github.com/elder-plinius/CL4R1T4S
    author: elder-plinius
    key_finding: "AI transparency project exposing hidden model instructions"

  - title: "BMAD-METHOD"
    url: https://github.com/bmad-code-org/BMAD-METHOD
    organization: BMad Code LLC
    key_finding: "Agile AI-driven dev framework with 21 agents and 50+ workflows"

  - title: "LLM Knowledge Cutoff Dates"
    url: https://github.com/HaoooWang/llm-knowledge-cutoff-dates
    author: HaoooWang
    key_finding: "Community-maintained summary of LLM knowledge cutoffs"

claude_code_issues:
  - title: "Web Search Capability Feature Request"
    url: https://github.com/anthropics/claude-code/issues/600
    organization: Anthropic
    key_finding: "Web search shipped and available"

  - title: "CLAUDE.md Context After Compact"
    url: https://github.com/anthropics/claude-code/issues/2714
    organization: Anthropic
    key_finding: "CLAUDE.md persists after compact as foundational context"

  - title: "/compact Loses CLAUDE.md Context"
    url: https://github.com/anthropics/claude-code/issues/4517
    organization: Anthropic
    key_finding: "Compact compresses history but doesn't preserve CLAUDE.md instructions"

  - title: "MAX_THINKING_TOKENS Forces Thinking Mode"
    url: https://github.com/anthropics/claude-code/issues/5257
    organization: Anthropic
    key_finding: "Environment variable forces thinking for all requests"

  - title: "SessionStart Hooks Don't Execute on First Run"
    url: https://github.com/anthropics/claude-code/issues/10997
    organization: Anthropic
    key_finding: "Hooks only execute after marketplace plugins cached locally"

security_research:
  - title: "GitHub Copilot Security and Privacy"
    url: https://blog.gitguardian.com/github-copilot-security-and-privacy/
    organization: GitGuardian
    key_finding: "Copilot repos have 40% higher secret leakage rate (6.4% vs 4.6%)"

  - title: "Breaking Instruction Hierarchy in gpt-4o-mini"
    url: https://embracethered.com/blog/posts/2024/chatgpt-gpt-4o-mini-instruction-hierarchie-bypasses/
    organization: Embrace The Red
    author: Johann Rehberger
    key_finding: "System instructions bypassable via persona switching and indirection"

  - title: "LLM01:2025 Prompt Injection - OWASP"
    url: https://genai.owasp.org/llmrisk/llm01-prompt-injection/
    organization: OWASP
    key_finding: "Top LLM security risk with direct and indirect variants"

  - title: "CBRN Red Teaming Study"
    url: https://www.enkryptai.com/company/resources/research-reports/red-teaming-cbrn
    organization: Enkrypt AI
    key_finding: "Critical safety gaps in frontier models pose immediate risks"

  - title: "AI Agent CBRN Vulnerabilities"
    url: https://www.activefence.com/blog/your-ai-agent-is-talking/
    organization: ActiveFence
    key_finding: "Non-experts trigger unsafe CBRN responses 25% of time, experts 45%+"

  - title: "New Jailbreaks for GitHub Copilot"
    url: https://www.darkreading.com/vulnerabilities-threats/new-jailbreaks-manipulate-github-copilot
    organization: Dark Reading
    key_finding: "Embedding chat in code bypasses restrictions, proxy captures API tokens"

  - title: "ChatGPT 4o System Prompt Leak"
    url: https://llmrefs.com/blog/chatgpt-system-prompt-leak
    organization: LLMrefs
    key_finding: "ChatGPT has no search index, only 4 trigger scenarios, 5 parallel queries"

  - title: "Claude 3.7 Sonnet System Prompt Leak"
    url: https://www.actuia.com/en/news/a-leak-reveals-the-entire-system-prompt-of-claude-37-sonnet/
    organization: ActuIA
    key_finding: "Constitutional AI approach with Universal Declaration of Human Rights values"

  - title: "Claude 4 System Prompt Analysis"
    url: https://simonwillison.net/2025/May/25/claude-4-system-prompt/
    author: Simon Willison
    key_finding: "Personality design, anti-sycophancy, copyright restrictions, full tool prompts"

  - title: "GPT-5 System Prompt Leak"
    url: https://www.digitaltrends.com/computing/you-are-chatgpt-leaked-system-prompt-reveals-the-inner-workings-of-gpt-5/
    organization: Digital Trends
    key_finding: "June 2024 cutoff, avoid 'Would you like me to' and 'Should I' phrases"

industry_analysis:
  - title: "LLMflation - LLM Inference Cost Trends"
    url: https://a16z.com/llmflation-llm-inference-cost/
    organization: Andreessen Horowitz (a16z)
    key_finding: "Inference cost decreasing 10x yearly, 1000x drop in 3 years since GPT-3"

  - title: "Rise of Autonomous Agents for Enterprise"
    url: https://aws.amazon.com/blogs/aws-insights/the-rise-of-autonomous-agents-what-enterprise-leaders-need-to-know-about-the-next-wave-of-ai/
    organization: AWS
    key_finding: "15% of work decisions by agentic AI by 2028, $52.6B market by 2030"

  - title: "LLM API Pricing Comparison 2025"
    url: https://intuitionlabs.ai/articles/llm-api-pricing-comparison-2025
    organization: IntuitionLabs
    key_finding: "DeepSeek $0.28/$0.42, OpenAI GPT-5 $1.25-$12 per 1M tokens"

  - title: "Anthropic API Pricing Breakdown"
    url: https://www.metacto.com/blogs/anthropic-api-pricing-a-full-breakdown-of-costs-and-integration
    organization: MetaCTO
    key_finding: "Claude 4.1 thinking tokens priced separately: Sonnet $5/$25/$10, Opus $20/$80/$40"

  - title: "AI Inference Costs Plunge"
    url: https://www.webpronews.com/ai-inference-costs-plunge-profit-path-for-openai-anthropic/
    organization: WebProNews
    key_finding: "OpenAI API pricing likely covers inference costs at volume, individual models profitable"

  - title: "How Much Do OpenAI and Anthropic Make?"
    url: https://www.wheresyoured.at/howmuchmoney/
    organization: Where's Your Ed At
    author: Ed Zitron
    key_finding: "OpenAI ~$3.6B in 2024, ~$5.3B through July 2025; Anthropic ~$1.5B through July 2025"

  - title: "AI Agents 2025: Expectations vs Reality"
    url: https://www.ibm.com/think/insights/ai-agents-2025-expectations-vs-reality
    organization: IBM
    key_finding: "99% of developers exploring agents, but true autonomous reasoning still maturing"

  - title: "AI Sycophancy Harming Science"
    url: https://www.nature.com/articles/d41586-025-03390-0
    organization: Nature
    key_finding: "AI 50% more sycophantic than humans, could cause immediate harm in healthcare"

  - title: "AI Sycophancy Research - Northeastern"
    url: https://news.northeastern.edu/2025/11/24/ai-sycophancy-research/
    organization: Northeastern University
    key_finding: "Bayesian framework shows sycophancy makes models more error-prone"

  - title: "AI Sycophancy Dark Pattern"
    url: https://techcrunch.com/2025/08/25/ai-sycophancy-isnt-just-a-quirk-experts-consider-it-a-dark-pattern-to-turn-users-into-profit/
    organization: TechCrunch
    key_finding: "Flattery and first-person pronouns fuel AI-related psychosis and delusions"

  - title: "Claude Code Sycophancy Frustration"
    url: https://www.theregister.com/2025/08/13/claude_codes_copious_coddling_confounds/
    organization: The Register
    key_finding: "48 open issues citing 'You're absolutely right!' despite Anthropic's 2023 research"

  - title: "Claude Code Gotchas"
    url: https://www.dolthub.com/blog/2025-06-30-claude-code-gotchas/
    organization: DoltHub
    key_finding: "Context compaction makes it 'dumber', gives up on large tasks, modifies tests"

  - title: "AutoML-Zero: AI Evolving Itself"
    url: https://www.science.org/content/article/artificial-intelligence-evolving-all-itself
    organization: Science / AAAS
    key_finding: "Google's AutoML-Zero uses evolution to develop AI with zero human input"

  - title: "Chinese AI Censorship Leak"
    url: https://techcrunch.com/2025/03/26/leaked-data-exposes-a-chinese-ai-censorship-machine/
    organization: TechCrunch
    key_finding: "133,000 examples for LLM-based censorship detecting subtle political criticism"

developer_productivity:
  - title: "Mythical Man Month 10 Lines Per Day"
    url: https://blog.ndepend.com/mythical-man-month-10-lines-per-developer-day/
    organization: NDepend
    key_finding: "Real-world data shows 80 LOC/day over 14 years, confirming Brooks"

  - title: "10 LOC Per Day - Skeptics"
    url: https://skeptics.stackexchange.com/questions/17224/do-professional-software-developers-write-an-average-of-10-lines-of-code-per-day
    organization: Stack Exchange
    key_finding: "Productivity varies 2-17 LOC/day for DoD projects"

  - title: "10 LOC Per Day - Stack Overflow"
    url: https://stackoverflow.com/questions/966800/mythical-man-month-10-lines-per-developer-day-how-close-on-large-projects
    organization: Stack Overflow
    key_finding: "Wide variance from negative LOC (refactoring) to 200+ on new projects"

  - title: "Claude Sonnet 4 in Copilot vs Claude Code"
    url: https://fbakkensen.github.io/ai/devtools/copilot/2025/08/16/claude-sonnet-4-in-gitHub-copilot-vs-claude-code-what-developers-need-to-know.html
    author: Flemming Bakkensen
    key_finding: "Same model behaves differently: Copilot ~128k context vs Claude Code full depth"

  - title: "GPT-5 Documentation Gap"
    url: https://community.openai.com/t/huge-gpt-5-documentation-gap-flaw-causing-bugs-input-tokens-exceed-the-configured-limit-of-272-000-tokens/1344734
    organization: OpenAI Community
    key_finding: "400k advertised, 272k input limit undocumented, causes production errors"

mcp_protocol:
  - title: "MCP Architecture Overview"
    url: https://modelcontextprotocol.io/docs/concepts/architecture
    organization: Anthropic / Linux Foundation
    key_finding: "JSON-RPC 2.0 protocol with initialization, tool discovery, execution, real-time updates"

third_party_claude:
  - title: "Claude Code Pricing Guide"
    url: https://claudelog.com/claude-code-pricing/
    organization: ClaudeLog
    key_finding: "Free, Pro $17-20/mo, Max $100-200/mo, API pricing comparison"

  - title: "Claude Code Auto-Compact Explained"
    url: https://claudelog.com/faqs/what-is-claude-code-auto-compact/
    organization: ClaudeLog
    key_finding: "Auto-compact summarizes at memory limits, instant compacting since v2.0.64"

  - title: "Claude Context Window Guide"
    url: https://www.datastudios.org/post/claude-context-window-token-limits-memory-policy-and-2025-rules
    organization: Data Studios
    key_finding: "200K tokens (500K Enterprise), system prompt/tools consume shared budget"

  - title: "Claude Web Search API Pricing"
    url: https://websearchapi.ai/blog/anthropic-claude-web-search-api
    organization: WebSearchAPI.ai
    key_finding: "$0.01 per search + token costs = $0.02-0.05 total per search"

  - title: "LLM Knowledge Cutoff Dates Guide"
    url: https://www.ofzenandcomputing.com/knowledge-cutoff-dates-llms/
    organization: Of Zen and Computing
    key_finding: "2-8 month gap between cutoff and release, effective knowledge trails further"

  - title: "Hallucinations in LLMs Guide"
    url: https://masterofcode.com/blog/hallucinations-in-llms-what-you-need-to-know-before-integration
    organization: Master of Code Global
    key_finding: "Hallucination rates fell from 38% (2021) to 8.2% (2026), best at 0.7%"

standards:
  - title: "Semantic Versioning 2.0.0"
    url: https://semver.org/
    organization: Tom Preston-Werner
    key_finding: "MAJOR.MINOR.PATCH for API change communication"

  - title: "RFC 2119: Requirement Level Keywords"
    url: https://www.rfc-editor.org/rfc/rfc2119
    organization: IETF
    date: 1997
    key_finding: "Defines MUST, SHALL, SHOULD, MAY interpretation in standards"

rust_documentation:
  - title: "Rust Packages, Crates, and Modules"
    url: https://doc.rust-lang.org/book/ch07-00-managing-growing-projects-with-packages-crates-and-modules.html
    organization: Rust Project
    key_finding: "Module system for organizing code through packages, crates, modules"

  - title: "Separating Modules into Different Files"
    url: https://doc.rust-lang.org/book/ch07-05-separating-modules-into-different-files.html
    organization: Rust Project
    key_finding: "Extract modules via mod declarations, compiler looks for matching filenames"

  - title: "redis-rs Crate Documentation"
    url: https://docs.rs/redis
    organization: docs.rs
    key_finding: "Rust Redis client with low/high-level APIs and async support"

database_comparison:
  - title: "CockroachDB vs Postgres"
    url: https://www.bytebase.com/blog/cockroachdb-vs-postgres/
    organization: Bytebase
    key_finding: "CockroachDB distributed but proprietary, PostgreSQL open-source with better single-node"

  - title: "YugabyteDB vs CockroachDB"
    url: https://www.yugabyte.com/yugabytedb-vs-cockroachdb/
    organization: Yugabyte
    key_finding: "YugabyteDB 85% PostgreSQL compatible vs CockroachDB 53%, Apache 2.0 license"
