posts:
- id: adr-054-brooks-law
  title: Brooks' Law for AI Agents
  url: https://github.com/royalbit/asimov/blob/main/docs/adr/054-dynamic-swarm-vs-fixed-agentic-frameworks.md
  x: |
    Brooks' Law applies to AI agents.

    "Adding manpower to a late software project makes it later." — Fred Brooks, 1975

    The formula: Communication channels = N × (N-1) / 2

    2 agents = 1 channel
    4 agents = 6 channels
    7 agents = 21 channels
    10 agents = 45 channels
    20 agents = 190 channels

    Google/MIT measured this for AI agents in December 2024:
    → Communication overhead scales with exponent 1.724
    → Maximum effective team size: 3-4 agents
    → Independent agents: 17.2x error amplification vs single-agent

    This is why LangChain, CrewAI, and other multi-agent frameworks hit a wall.

    They fragment context across agents. Each agent gets 8-32k tokens. They coordinate through external infrastructure—state machines, message queues, databases.

    Every handoff loses information. Every coordination point adds latency. Every agent has a different view of the problem.

    The pattern that works: One large context where AI decides when to spawn agents.

    O(1) coordination vs O(n^1.724).

    We documented this with 50+ verified references:
    https://github.com/royalbit/asimov/blob/main/docs/adr/054-dynamic-swarm-vs-fixed-agentic-frameworks.md

    #AI #Agents #SoftwareEngineering
  linkedin: |
    Brooks' Law applies to AI agents.

    "Adding manpower to a late software project makes it later." — Fred Brooks, 1975

    The math is brutal:
    - 4 agents = 6 communication channels  - manageable
    - 10 agents = 45 channels  - chaos
    - 20 agents = 190 channels  - impossible

    Google/MIT measured it in December 2024:
    - Communication overhead scales with exponent 1.724
    - Maximum effective team size: 3-4 agents
    - Independent agents show 17.2x error amplification vs single-agent baseline

    This explains why multi-agent frameworks hit a wall.

    They fragment context across agents. Each agent gets 8-32k tokens. They coordinate through external infrastructure—state machines, message queues, databases.

    Every handoff loses information. Every coordination point adds latency. Every agent has a different view of the problem.

    The pattern that works: One large context - 200k+ tokens where the AI decides when to spawn agents.

    Context IS the coordination layer.

    No serialization. No translation errors. No "telephone game" between agents.

    We spent a week documenting this with 50+ verified references:
    https://github.com/royalbit/asimov/blob/main/docs/adr/054-dynamic-swarm-vs-fixed-agentic-frameworks.md

    #AI #Agents #SoftwareEngineering #MultiAgent
  posted:
    x: 2026-01-01T03:08:05.106085793+00:00
- id: adr-054-cognition-quote
  title: Devin's Creators on Multi-Agent
  url: https://github.com/royalbit/asimov/blob/main/docs/adr/054-dynamic-swarm-vs-fixed-agentic-frameworks.md
  x: |
    Last year, Cognition—the team behind Devin, the most hyped AI coding agent—published this:

    "In 2025, running multiple agents in collaboration only results in fragile systems. The decision-making ends up being too dispersed and context isn't able to be shared thoroughly enough between the agents."

    They built the hype. Then said don't.

    Their recommendation:
    1. All agents should read from the same context
    2. All agents should write to the same context

    As we enter 2026, this still holds. The research confirms it:
    → Full-file context: 95% accuracy
    → Fragmented retrieval: 80% accuracy

    That 15% gap compounds over steps. By step 10, fragmented systems have an 89% failure rate.

    Cognition learned it the hard way. Google/MIT confirmed it. The math proves it.

    Source: https://cognition.ai/blog/dont-build-multi-agents

    We compiled the research with 50+ verified refs:
    https://github.com/royalbit/asimov/blob/main/docs/adr/054-dynamic-swarm-vs-fixed-agentic-frameworks.md

    #AI #Devin #Agents
  linkedin: |
    Last year, the team behind Devin—the most hyped AI coding agent—published this:

    "In 2025, running multiple agents in collaboration only results in fragile systems. The decision-making ends up being too dispersed and context isn't able to be shared thoroughly enough between the agents."

    Their recommendation:
    1. All agents should read from the same context
    2. All agents should write to the same context

    As we enter 2026, this still holds. The research confirms it:
    - Full-file context: 95% accuracy
    - Fragmented retrieval: 80% accuracy

    That 15% gap compounds over steps. By step 10, it's the difference between shipping and debugging.

    Cognition learned it the hard way. Google/MIT confirmed it. The math proves it.

    Source: https://cognition.ai/blog/dont-build-multi-agents

    We compiled the research - 50+ refs:
    https://github.com/royalbit/asimov/blob/main/docs/adr/054-dynamic-swarm-vs-fixed-agentic-frameworks.md

    #AI #Agents #Devin #SoftwareEngineering
  posted:
    x: 2026-01-01T03:08:17.430472176+00:00
- id: adr-054-accuracy-gap
  title: 95% vs 80% - The Coherence Gap
  url: https://github.com/royalbit/asimov/blob/main/docs/adr/054-dynamic-swarm-vs-fixed-agentic-frameworks.md
  x: |
    The number that should change how you think about AI agents.

    On SWE-bench-Verified:
    → Full-file context: 95% accuracy
    → Fragmented retrieval: 80% accuracy

    15 percentage points. Same task. Same model. Different architecture.

    The difference comes from coherence.

    With full files, the model sees relationships across the entire document. Variable definitions. Function calls. Import statements. The whole picture.

    With fragmented retrieval, the model stitches together disjointed pieces. Context is lost at every boundary.

    Agent A sees the function signature.
    Agent B sees the implementation.
    Agent C sees the tests.

    None of them see the whole.

    The "Rule of 4" from Google/MIT:
    → Maximum effective team size: 3-4 agents
    → Beyond that, coordination overhead dominates
    → 17.2x error amplification with independent agents

    The fix isn't better coordination infrastructure.

    The fix is not fragmenting context in the first place.

    Research with 50+ verified refs:
    https://github.com/royalbit/asimov/blob/main/docs/adr/054-dynamic-swarm-vs-fixed-agentic-frameworks.md

    #AI #SWEbench #Coding
  linkedin: |
    The number that should change how you think about AI agents.

    On SWE-bench-Verified:
    - Full-file context: 95% accuracy
    - Fragmented retrieval: 80% accuracy

    15 percentage points. Same task. Same model. Different architecture.

    The difference comes from coherence.

    With full files, the model sees relationships across the entire document. Variable definitions. Function calls. Import statements. The whole picture.

    With fragmented retrieval - RAG, multi-agent handoffs, the model stitches together disjointed pieces. Context is lost at every boundary. Relationships are severed.

    This is why multi-agent systems struggle with complex reasoning.

    Agent A sees the function signature.
    Agent B sees the implementation.
    Agent C sees the tests.

    None of them see the whole.

    The "Rule of 4" from Google/MIT research:
    - Maximum effective team size: 3-4 agents
    - Beyond that, coordination overhead dominates
    - 17.2x error amplification with independent agents

    The fix isn't better coordination infrastructure.

    The fix is not fragmenting context in the first place.

    Research - 50+ verified refs:
    https://github.com/royalbit/asimov/blob/main/docs/adr/054-dynamic-swarm-vs-fixed-agentic-frameworks.md

    #AI #SWEbench #Coding #SoftwareEngineering
  posted:
    x: 2026-01-01T03:08:21.328331535+00:00
- id: adr-054-research-summary
  title: Multi-Agent Research Summary
  url: https://github.com/royalbit/asimov/blob/main/docs/adr/054-dynamic-swarm-vs-fixed-agentic-frameworks.md
  x: |
    We spent a week gathering hard data on multi-agent AI architectures.

    50+ verified references. Real benchmarks. Peer-reviewed research.

    The findings:

    1. Brooks' Law applies to AI agents
    Communication overhead = N × (N-1) / 2
    Google/MIT measured: exponent 1.724

    2. Full context crushes fragmented
    SWE-bench: 95% vs 80% accuracy
    The 15% gap is coherence

    3. The Rule of 4
    Max effective team: 3-4 agents
    Beyond that, coordination overhead dominates

    4. Multi-agent token overhead
    Anthropic's research: 15x more tokens than single-agent
    Token usage explains 80% of performance variance

    5. Cognition agrees
    "Running multiple agents only results in fragile systems."

    The implication:

    Fixed agent frameworks are engineering complexity around a fundamental limitation. They fragment context to work within smaller windows.

    The pattern that works: One large context. AI decides when to spawn agents.

    O(1) coordination vs O(n^1.724).

    Full research:
    https://github.com/royalbit/asimov/blob/main/docs/adr/054-dynamic-swarm-vs-fixed-agentic-frameworks.md

    #AI #Agents #Research
  linkedin: |
    We spent a week gathering hard data on multi-agent AI architectures. 50+ verified references. Real benchmarks. Peer-reviewed research.

    The findings:

    1. Brooks' Law applies to AI agents
    Communication overhead = N × (N-1) / 2
    Google/MIT measured: exponent 1.724 - worse than quadratic

    2. Full context crushes fragmented
    SWE-bench-Verified: 95% vs 80% accuracy
    The 15% gap is coherence—relationships across the whole, not stitched fragments

    3. The Rule of 4
    Maximum effective team size: 3-4 agents
    Beyond that, coordination overhead dominates performance gains

    4. Multi-agent token overhead
    Anthropic's own research: 15x more tokens than single-agent chat
    Token usage explains 80% of performance variance

    5. Cognition - Devin - agrees
    "Running multiple agents in collaboration only results in fragile systems."

    The implication:

    Fixed agent frameworks are engineering complexity around a fundamental limitation. They fragment context to work within smaller windows. They build coordination infrastructure to reconnect what should never have been separated.

    The pattern that works: One large context. AI decides when to spawn agents. Context IS the coordination layer.

    O(1) coordination vs O(n^1.724).

    Full research:
    https://github.com/royalbit/asimov/blob/main/docs/adr/054-dynamic-swarm-vs-fixed-agentic-frameworks.md

    #AI #Agents #SoftwareEngineering #Research #MultiAgent
  posted:
    x: 2026-01-01T03:08:26.156896489+00:00
- id: adr-054-rag-vs-context
  title: RAG vs Long Context - The Data
  url: https://github.com/royalbit/asimov/blob/main/docs/adr/054-dynamic-swarm-vs-fixed-agentic-frameworks.md
  x: |
    RAG was a workaround for small context windows. The workaround is becoming obsolete.

    Google DeepMind, July 2024:
    → Long context outperforms RAG by 7-13% on average
    → GPT-4O: +13.1% with full context
    → Gemini-1.5-Pro: +7.6% with full context

    RAG failure patterns:
    1. Multi-step reasoning: Query requires previous step results
    2. General queries: Too vague for effective retrieval
    3. Implicit queries: Requires holistic context understanding
    4. Long/complex queries: Challenging for retriever to parse

    The cost trade-off:
    → RAG: 4% of long-context cost
    → Long context: 25x more expensive

    But for code understanding, the accuracy gap is 95% vs 80%.

    That 15% is the difference between shipping and debugging for hours.

    For high-value tasks—code generation, complex reasoning, multi-step analysis—the 25x cost premium pays for itself.

    RAG still wins for dynamic data and simple lookups.

    But for reasoning? For code? Use the context window.

    Original research: https://arxiv.org/abs/2407.16833

    Our analysis with 50+ refs:
    https://github.com/royalbit/asimov/blob/main/docs/adr/054-dynamic-swarm-vs-fixed-agentic-frameworks.md

    #AI #RAG #LLM
  linkedin: |
    RAG was a workaround for small context windows. The workaround is becoming obsolete.

    Google DeepMind, July 2024:
    - Long context outperforms RAG by 7-13% on average
    - GPT-4O: +13.1% with full context
    - Gemini-1.5-Pro: +7.6% with full context

    RAG failure patterns from the research:
    1. Multi-step reasoning: Query requires previous step results for retrieval
    2. General queries: Too vague for effective retrieval
    3. Implicit queries: Requires holistic context understanding
    4. Long/complex queries: Challenging for retriever to parse

    The cost trade-off:
    - RAG: 4% of long-context cost
    - Long context: 25x more expensive

    But here's the thing:

    For code understanding, the accuracy gap is 95% vs 80% - SWE-bench.

    That 15% is the difference between shipping and debugging for hours.

    For high-value tasks—code generation, complex reasoning, multi-step analysis—the 25x cost premium pays for itself in accuracy and developer time.

    RAG still wins for:
    - Dynamic/frequently updated data
    - Cost-sensitive applications
    - Simple lookups

    But for reasoning? For code? For complex analysis?

    Use the context window.

    Original research: https://arxiv.org/abs/2407.16833

    Our analysis - 50+ refs:
    https://github.com/royalbit/asimov/blob/main/docs/adr/054-dynamic-swarm-vs-fixed-agentic-frameworks.md

    #AI #RAG #LLM #SoftwareEngineering #Research
  posted:
    x: 2026-01-01T03:08:32.274924506+00:00
- id: error-compounding-math
  title: 5,391x - Error Compounding
  url: https://github.com/royalbit/asimov/blob/main/models/error-compounding.yaml
  x: |
    5,391x. Not a typo.

    That's the gap between full context and fragmented at 50 steps.

    The 95% vs 80% accuracy gap isn't 15 percentage points. Errors compound multiplicatively.

    The formula: P(success after N steps) = accuracy^N

    At 1 step:
    → 80%: 80% success | 95%: 95% success | Gap: 1.2x

    At 5 steps:
    → 80%: 32.8% success | 95%: 77.4% success | Gap: 2.4x

    At 10 steps:
    → 80%: 10.7% success | 95%: 59.9% success | Gap: 5.6x

    At 20 steps:
    → 80%: 1.2% success | 95%: 35.8% success | Gap: 31x

    At 50 steps:
    → 80%: 0.001% success | 95%: 7.7% success | Gap: 5,391x

    This is why multi-agent systems collapse on complex tasks.

    Each agent handoff is a step. Each step compounds the error.

    We modeled this deterministically with Forge:
    https://github.com/royalbit/asimov/blob/main/models/error-compounding.yaml

    Full research:
    https://github.com/royalbit/asimov/blob/main/docs/adr/054-dynamic-swarm-vs-fixed-agentic-frameworks.md

    The math doesn't lie.

    #AI #Math #Agents
  linkedin: |
    The 95% vs 80% accuracy gap isn't 15 percentage points.

    Errors compound multiplicatively.

    The formula: P(success after N steps) = accuracy^N

    Here's what that means in practice:

    At 1 step:
    - 80% accuracy: 80% success
    - 95% accuracy: 95% success
    - Gap: 1.2x

    At 10 steps - typical complex task:
    - 80% accuracy: 10.7% success
    - 95% accuracy: 59.9% success
    - Gap: 5.6x

    At 20 steps - large feature:
    - 80% accuracy: 1.2% success
    - 95% accuracy: 35.8% success
    - Gap: 31x

    At 50 steps - system integration:
    - 80% accuracy: 0.001% success
    - 95% accuracy: 7.7% success
    - Gap: 5,391x

    This is why multi-agent systems collapse on complex tasks.

    Each agent handoff is a step. Each step compounds the error.

    We modeled this deterministically:
    https://github.com/royalbit/asimov/blob/main/models/error-compounding.yaml

    The math doesn't lie.

    #AI #Agents #Math #SoftwareEngineering
  posted:
    x: 2026-01-01T03:08:39.603405351+00:00
- id: error-compounding-89-percent
  title: 89% Failure Rate
  url: https://github.com/royalbit/asimov/blob/main/docs/adr/054-dynamic-swarm-vs-fixed-agentic-frameworks.md
  x: |
    89% failure rate.

    That's fragmented context at 10 steps—a typical complex coding task.

    Full context? 40% failure rate.

    Same steps. Same task. Different architecture.

    The difference is error compounding.

    When accuracy is 80% per step:
    → Step 1: 80% success
    → Step 5: 32.8% success
    → Step 10: 10.7% success ← 89% failure

    When accuracy is 95% per step:
    → Step 1: 95% success
    → Step 5: 77.4% success
    → Step 10: 59.9% success ← 40% failure

    This explains why multi-agent frameworks hit a wall on complex tasks.

    They fragment context. Each agent handoff is a step. Each step compounds the 20% error rate.

    By step 10, you're essentially guaranteed to fail.

    The pattern that works: One large context. AI decides when to spawn agents. Context IS the coordination layer.

    Deterministic model:
    https://github.com/royalbit/asimov/blob/main/models/error-compounding.yaml

    Research with 50+ verified refs:
    https://github.com/royalbit/asimov/blob/main/docs/adr/054-dynamic-swarm-vs-fixed-agentic-frameworks.md

    #AI #Agents #MultiAgent
  linkedin: |
    At 10 steps—a typical complex coding task—fragmented context systems have an 89% failure rate.

    Full context systems? 40% failure rate.

    Same steps. Same task. Different architecture.

    The difference is error compounding.

    When accuracy is 80% per step - fragmented/multi-agent:
    - Step 1: 80% success
    - Step 5: 32.8% success
    - Step 10: 10.7% success ← 89% failure

    When accuracy is 95% per step - full context:
    - Step 1: 95% success
    - Step 5: 77.4% success
    - Step 10: 59.9% success ← 40% failure

    This explains why multi-agent frameworks hit a wall on complex tasks.

    They fragment context. Each agent handoff is a step. Each step compounds the 20% error rate.

    By step 10, you're essentially guaranteed to fail.

    The pattern that works: One large context - 200k+ tokens. AI decides when to spawn agents. Context IS the coordination layer.

    Research - 50+ verified refs:
    https://github.com/royalbit/asimov/blob/main/docs/adr/054-dynamic-swarm-vs-fixed-agentic-frameworks.md

    #AI #Agents #MultiAgent #SoftwareEngineering
  posted:
    x: 2026-01-01T03:08:48.000743448+00:00
